{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b510404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris#数据\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV#划分数据集\n",
    "from sklearn.preprocessing import StandardScaler#数据标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e8c7d",
   "metadata": {},
   "source": [
    "# 线性回归算法\n",
    "线性回归是一种用于建模目标变量与一个或多个特征变量之间关系的统计方法。\n",
    "\n",
    "其公式为：\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_n x_n + \\epsilon $$\n",
    "\n",
    "其中：\n",
    "- $y$ 是目标变量\n",
    "- $x_1, x_2, \\dots, x_n$ 是特征变量\n",
    "- $\\beta_0$ 是截距\n",
    "- $\\beta_1, \\beta_2, \\dots, \\beta_n$ 是回归系数\n",
    "- $\\epsilon$ 是误差项"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976403b",
   "metadata": {},
   "source": [
    "# 线性关系和非线性关系\n",
    "在数据分析中，变量之间的关系可以分为线性关系和非线性关系。\n",
    "\n",
    "## 线性关系\n",
    "线性关系是指两个变量之间的关系可以用一条直线来表示，其数学表达式为：\n",
    "\n",
    "$$ y = mx + c $$\n",
    "\n",
    "其中：\n",
    "- $m$ 是斜率，表示变量变化的速率\n",
    "- $c$ 是截距，表示直线与 $y$ 轴的交点\n",
    "\n",
    "## 非线性关系\n",
    "非线性关系是指两个变量之间的关系不能用一条直线来表示，而是需要用曲线来描述。例如：\n",
    "\n",
    "- 二次关系：$$ y = ax^2 + bx + c $$\n",
    "- 指数关系：$$ y = a e^{bx} $$\n",
    "- 对数关系：$$ y = a \\ln(x) + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f261aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d992ef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([86.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[[80,86],[82,80],[85,78],[90,90],[86,82],[82,90],[78,80]]\n",
    "y=[84.2,80.6,80.1,90,83.2,87.6,79.4]\n",
    "estimator=LinearRegression()\n",
    "estimator.fit(x,y)\n",
    "estimator.coef_\n",
    "estimator.predict([[100,80]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ac6de",
   "metadata": {},
   "source": [
    "这段代码展示了如何使用 `sklearn` 库中的 `LinearRegression` 类来进行线性回归建模和预测。以下是代码的逐步解释：\n",
    "\n",
    "1. **定义输入数据和目标变量**：\n",
    "   ```python\n",
    "   x=[[80,86],[82,80],[85,78],[90,90],[86,82],[82,90],[78,80]]\n",
    "   y=[84.2,80.6,80.1,90,83.2,87.6,79.4]\n",
    "   ```\n",
    "   - `x` 是一个二维列表，表示特征变量的值，每个子列表包含两个特征。\n",
    "   - `y` 是目标变量的值，与 `x` 中的每一行对应。\n",
    "\n",
    "2. **创建线性回归模型**：\n",
    "   ```python\n",
    "   estimator=LinearRegression()\n",
    "   ```\n",
    "   - 使用 `LinearRegression()` 创建一个线性回归模型实例 `estimator`。\n",
    "\n",
    "3. **拟合模型**：\n",
    "   ```python\n",
    "   estimator.fit(x,y)\n",
    "   ```\n",
    "   - 使用 `fit` 方法将模型拟合到数据 `x` 和 `y` 上。模型会学习特征与目标变量之间的关系。\n",
    "\n",
    "4. **获取回归系数**：\n",
    "   ```python\n",
    "   estimator.coef_\n",
    "   ```\n",
    "   - `coef_` 属性返回模型的回归系数（即每个特征的权重）。这些系数表示每个特征对目标变量的影响程度。\n",
    "\n",
    "5. **进行预测**：\n",
    "   ```python\n",
    "   estimator.predict([[100,80]])\n",
    "   ```\n",
    "   - 使用 `predict` 方法对新的输入数据 `[[100,80]]` 进行预测，返回预测的目标变量值。\n",
    "\n",
    "总结来说，这段代码通过线性回归模型对给定的特征和目标变量进行建模，并使用训练好的模型对新数据进行预测。\n",
    "\n",
    "找到具有 1 个许可证类型的类似代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c022302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(estimator.coef_)#打印对应线性回归系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55802484",
   "metadata": {},
   "source": [
    "# 线性回归的损失和优化\n",
    "在线性回归中，模型的目标是找到一组回归系数，使得预测值与真实值之间的误差最小。\n",
    "\n",
    "## 损失函数\n",
    "线性回归通常使用均方误差（Mean Squared Error, MSE）作为损失函数，其定义为：\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "其中：\n",
    "- $n$ 是样本数量\n",
    "- $y_i$ 是第 $i$ 个样本的真实值\n",
    "- $\\hat{y}_i$ 是第 $i$ 个样本的预测值\n",
    "\n",
    "MSE 衡量了模型预测值与真实值之间的平均平方误差，值越小表示模型的拟合效果越好。\n",
    "\n",
    "## 优化方法\n",
    "为了最小化损失函数，线性回归通常使用以下两种优化方法：\n",
    "\n",
    "1. **正规方程**：\n",
    "   - 对于普通最小二乘法（OLS），可以通过解析解直接计算回归系数：\n",
    "     $$ \\beta = (X^T X)^{-1} X^T y $$\n",
    "   - 这种方法计算速度快，但当特征数量较多或矩阵不可逆时可能不适用。\n",
    "   - 不能解决拟合问题,小规模数据\n",
    "\n",
    "2. **梯度下降**：\n",
    "   - 通过迭代优化的方法逐步更新回归系数：\n",
    "     $$ \\beta := \\beta - \\eta \\nabla L(\\beta) $$\n",
    "   - 其中 $\\eta$ 是学习率，$\\nabla L(\\beta)$ 是损失函数的梯度。\n",
    "   - 梯度下降适用于大规模数据集，但需要选择合适的学习率以确保收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d78ec",
   "metadata": {},
   "source": [
    "# 梯度下降的定义和公式\n",
    "梯度下降是一种优化算法，用于通过迭代的方式最小化目标函数（例如损失函数）。\n",
    "\n",
    "## 定义\n",
    "梯度下降的核心思想是沿着目标函数梯度的反方向更新参数，因为梯度的方向表示函数值增长最快的方向，而反方向则是函数值减小最快的方向。\n",
    "\n",
    "## 公式\n",
    "对于一个目标函数 $L(\\beta)$，梯度下降的更新公式为：\n",
    "\n",
    "$$ \\beta := \\beta - \\eta \\nabla L(\\beta) $$\n",
    "\n",
    "其中：\n",
    "- $\\beta$ 是需要优化的参数（例如线性回归中的回归系数）\n",
    "- $\\eta$ 是学习率，控制每次更新的步长\n",
    "- $\\nabla L(\\beta)$ 是目标函数 $L(\\beta)$ 对参数 $\\beta$ 的梯度,目标函数的微分\n",
    "\n",
    "## 梯度计算\n",
    "以线性回归的均方误差（MSE）为例，其梯度为：\n",
    "\n",
    "$$ \\nabla L(\\beta) = -\\frac{2}{n} X^T (y - X \\beta) $$\n",
    "\n",
    "通过不断更新参数 $\\beta$，梯度下降算法可以逐步逼近目标函数的最小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80ea0c",
   "metadata": {},
   "source": [
    "# 正规方程推导\n",
    "在线性回归中，目标是最小化损失函数（通常是均方误差）：\n",
    "\n",
    "$$ L(\\beta) = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n (y_i - X_i \\beta)^2 $$\n",
    "\n",
    "其中：\n",
    "- $y_i$ 是目标变量的真实值\n",
    "- $\\hat{y}_i = X_i \\beta$ 是预测值\n",
    "- $X_i$ 是特征矩阵的第 $i$ 行\n",
    "- $\\beta$ 是回归系数向量\n",
    "\n",
    "将损失函数展开并向量化表示：\n",
    "\n",
    "$$ L(\\beta) = (y - X \\beta)^T (y - X \\beta) $$\n",
    "\n",
    "对 $\\beta$ 求导并令导数为 0：\n",
    "\n",
    "$$ \\frac{\\partial L(\\beta)}{\\partial \\beta} = -2 X^T (y - X \\beta) = 0 $$\n",
    "\n",
    "解得：\n",
    "\n",
    "$$ \\beta = (X^T X)^{-1} X^T y $$\n",
    "\n",
    "这就是线性回归的正规方程。通过正规方程可以直接计算回归系数，无需迭代优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "732d03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=LinearRegression(fit_intercept=False)#是否偏置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9834d8",
   "metadata": {},
   "source": [
    "# 线性回归示例\n",
    "本示例展示如何使用 `LinearRegression` 进行建模，并通过均方误差（MSE）和 $R^2$ 分数评估模型性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954794ea",
   "metadata": {},
   "source": [
    "正规方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20429754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个模型偏置是:\n",
      " -5.592988384093377\n",
      "这个模型的系数是:\n",
      " [40.01091848]\n",
      "均方误差 (MSE): 191.65201592081098\n",
      "R^2 分数: 0.884891993144589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 生成回归数据集\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#正则化\n",
    "transfer=StandardScaler()\n",
    "X_test=transfer.fit_transform(X_test)\n",
    "X_train=transfer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# 创建线性回归模型并训练\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('这个模型偏置是:\\n',model.intercept_)\n",
    "print('这个模型的系数是:\\n',model.coef_)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 模型评估\n",
    "mse = mean_squared_error(y_test, y_pred)#均方误差\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"均方误差 (MSE): {mse}\")\n",
    "print(f\"R^2 分数: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5630a8",
   "metadata": {},
   "source": [
    "梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e4d4939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个模型偏置是:\n",
      " [-3.52355131]\n",
      "这个模型的系数是:\n",
      " [40.91561444]\n",
      "均方误差 (MSE): 152.68246898321968\n",
      "R^2 分数: 0.908297470277154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 生成回归数据集\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#正则化\n",
    "transfer=StandardScaler()\n",
    "X_test=transfer.fit_transform(X_test)\n",
    "X_train=transfer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# 创建线性回归模型并训练\n",
    "model = SGDRegressor(max_iter=1000,learning_rate='constant',eta0=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "print('这个模型偏置是:\\n',model.intercept_)\n",
    "print('这个模型的系数是:\\n',model.coef_)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 模型评估\n",
    "mse = mean_squared_error(y_test, y_pred)#均方误差\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"均方误差 (MSE): {mse}\")\n",
    "print(f\"R^2 分数: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ef047",
   "metadata": {},
   "source": [
    "`make_regression` 是 `scikit-learn` 提供的一个函数，用于生成用于回归分析的合成数据集。它可以快速创建具有指定特性的数据集，方便测试和验证回归模型。\n",
    "\n",
    "通过 `make_regression`，用户可以控制数据集的样本数量、特征数量、噪声水平等。例如，可以生成一个包含线性关系的目标变量和特征变量的数据集，并添加一定的随机噪声以模拟真实数据的复杂性。\n",
    "\n",
    "这个函数特别适合用于机器学习模型的实验和调试，因为它提供了一个可控的环境来测试模型的性能和行为。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3e14f",
   "metadata": {},
   "source": [
    "`SGDRegressor` 是 `scikit-learn` 中的一个线性模型，用于执行带有随机梯度下降优化的线性回归。该模型通过迭代的方式更新参数，以最小化损失函数（如均方误差）。\n",
    "\n",
    "在这段代码中，`max_iter=1000` 指定了模型最多迭代 1000 次，以确保模型有足够的机会收敛到最优解。如果在迭代过程中损失函数的变化小于某个阈值，训练可能会提前停止。\n",
    "\n",
    "参数 `learning_rate='constant'` 表示学习率保持固定值，不会随着迭代次数动态调整。`eta0=0.1` 则定义了初始学习率的值为 0.1。学习率控制了每次参数更新的步长，较大的学习率可能导致收敛不稳定，而较小的学习率可能导致收敛速度较慢。\n",
    "\n",
    "通过这种配置，模型在每次迭代中使用随机样本计算梯度并更新参数，从而在效率和性能之间取得平衡，特别适用于大规模数据集。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
