{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c35630a",
   "metadata": {},
   "source": [
    "# 决策树学习\n",
    "决策树是一种常用的监督学习算法，适用于分类和回归任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ac76d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率: 1.00\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据集\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建并训练决策树模型\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 测试模型\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f'模型准确率: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481e7c0",
   "metadata": {},
   "source": [
    "## 信息熵、信息增益率和基尼系数\n",
    "在决策树中，信息熵用于衡量数据的不确定性，信息增益率用于选择最优划分属性，基尼系数用于评估数据集的纯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86937c4",
   "metadata": {},
   "source": [
    "## 信息熵、信息增益率和基尼系数的定义和公式\n",
    "### 信息熵 (Entropy)\n",
    "信息熵是衡量数据集不确定性的一种指标，其公式为：\n",
    "$$ Entropy = -\\sum_{i=1}^{n} p_i \\log_2(p_i) $$\n",
    "其中，$p_i$ 是类别 $i$ 的概率。\n",
    "\n",
    "### 信息增益率 (Information Gain Ratio)\n",
    "信息增益率用于衡量某一特征对数据集划分的有效性，其公式为：\n",
    "$$ GainRatio = \\frac{Gain}{IV} $$\n",
    "其中，$Gain$ 是信息增益，$IV$ 是固有值 (Intrinsic Value)。\n",
    "\n",
    "### 基尼系数 (Gini Index)\n",
    "基尼系数用于衡量数据集的纯度，其公式为：\n",
    "$$ Gini = 1 - \\sum_{i=1}^{n} p_i^2 $$\n",
    "其中，$p_i$ 是类别 $i$ 的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed71f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息熵: 0.9852\n"
     ]
    }
   ],
   "source": [
    "# 计算信息熵\n",
    "#当数据量一定时，系统越有序，熵值越低，系统越混乱，熵值越高\n",
    "from math import log2\n",
    "\n",
    "def entropy(labels):\n",
    "    total = len(labels)\n",
    "    counts = {label: labels.count(label) for label in set(labels)}\n",
    "    return -sum((count / total) * log2(count / total) for count in counts.values())\n",
    "\n",
    "# 示例数据\n",
    "labels = [0, 0, 1, 1, 1, 0, 1]\n",
    "print(f'信息熵: {entropy(labels):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80f5f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基尼系数: 0.4898\n"
     ]
    }
   ],
   "source": [
    "# 计算基尼系数\n",
    "def gini(labels):\n",
    "    total = len(labels)\n",
    "    counts = {label: labels.count(label) for label in set(labels)}\n",
    "    return 1 - sum((count / total) ** 2 for count in counts.values())\n",
    "\n",
    "# 示例数据\n",
    "print(f'基尼系数: {gini(labels):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce62d547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息增益率: 0.1300\n"
     ]
    }
   ],
   "source": [
    "# 计算信息增益率\n",
    "def information_gain_ratio(parent_entropy, subsets):\n",
    "    total = sum(len(subset) for subset in subsets)\n",
    "    weighted_entropy = sum((len(subset) / total) * entropy(subset) for subset in subsets)\n",
    "    intrinsic_value = -sum((len(subset) / total) * log2(len(subset) / total) for subset in subsets if len(subset) > 0)\n",
    "    gain = parent_entropy - weighted_entropy\n",
    "    return gain / intrinsic_value if intrinsic_value != 0 else 0\n",
    "\n",
    "# 示例数据\n",
    "subset1 = [0, 0, 1]\n",
    "subset2 = [1, 1, 0, 1]\n",
    "parent_entropy = entropy(labels)\n",
    "gain_ratio = information_gain_ratio(parent_entropy, [subset1, subset2])\n",
    "print(f'信息增益率: {gain_ratio:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ab8ff",
   "metadata": {},
   "source": [
    "## 篮球比赛熵值计算\n",
    "假设有4个球队 {A, B, C, D}，它们的获胜概率分别为 {1/2, 1/4, 1/8, 1/8}，计算其熵值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ade2ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "篮球比赛的熵值 Ent(D): 1.7500\n"
     ]
    }
   ],
   "source": [
    "# 计算熵值\n",
    "probabilities = [1/2, 1/4, 1/8, 1/8]\n",
    "entropy_value = -sum(p * log2(p) for p in probabilities)\n",
    "print(f'篮球比赛的熵值 Ent(D): {entropy_value:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
