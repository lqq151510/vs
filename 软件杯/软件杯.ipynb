{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea63603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib as plt\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76e47e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('test.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec708017",
   "metadata": {},
   "source": [
    "异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d69f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_feature_engineering(df):\n",
    "#     \"\"\"\n",
    "#     这段代码用于处理股票数据中的异常值，分为两部分：\n",
    "\n",
    "#     1. **IQR 法处理价格异常值**  \n",
    "#        - 针对“开盘”、“最高”、“最低”、“收盘”四个价格列，使用四分位数间距（IQR）方法检测和修正异常值。\n",
    "#        - 具体做法是：  \n",
    "#          - 计算每列的第 1 四分位数（Q1）和第 3 四分位数（Q3）。\n",
    "#          - 计算 IQR = Q3 - Q1。\n",
    "#          - 定义下界为 Q1 - 1.5*IQR，上界为 Q3 + 1.5*IQR。\n",
    "#          - 将低于下界的值替换为下界，高于上界的值替换为上界，其他值保持不变。\n",
    "#        - 这样可以有效减少极端异常值对后续分析的影响。\n",
    "\n",
    "#     2. **Z-score 法处理成交量异常值**  \n",
    "#        - 对“成交量”列，采用 Z-score 方法检测异常值。\n",
    "#        - 计算成交量的均值和标准差，将绝对偏离均值超过 3 个标准差的值视为异常。\n",
    "#        - 对于异常值，用成交量的中位数进行替换。\n",
    "#        - 这种方法适合处理近似正态分布的数据，能有效缓解极端值的影响。\n",
    "\n",
    "#     整体来看，这段代码的目的是通过合理的异常值处理，提高数据质量，为后续的特征工程和建模打下基础。\n",
    "#      \"\"\"\n",
    "#     df['日期']=pd.to_datetime(df['日期'])\n",
    "#       #IQR法处理价格异常值\n",
    "#     price=['开盘','最高','最低','收盘']\n",
    "#     for col in price:\n",
    "#         q1=df[col].quantile(0.25)\n",
    "#         q3=df[col].quantile(0.75)\n",
    "#         iqr=q3-q1\n",
    "#         lower_bound=q1-1.5*iqr\n",
    "#         upper_bound=q3+1.5*iqr\n",
    "#         df[col]=np.where(df[col]<lower_bound,lower_bound,np.where(df[col]>upper_bound,upper_bound,df[col]))\n",
    "\n",
    "\n",
    "#     #Z-score处理成交量异常值\n",
    "#     volume_mean=df['成交量'].mean()\n",
    "#     volume_std=df['成交量'].std()\n",
    "#     df['成交量']=np.where(np.abs(df['成交量']-volume_mean)>3*volume_std,df['成交量'].median(),df['成交量'])\n",
    "#     return df\n",
    "# df=stock_feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2eb7da",
   "metadata": {},
   "source": [
    "时间特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e299ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df['周内日'] = df['日期'].dt.dayofweek\n",
    "# df['月份'] = df['日期'].dt.month\n",
    "# df['年份'] = df['日期'].dt.year\n",
    "# df['季度'] = df['月份'].map({\n",
    "#     12: 0, 1: 0, 2: 0,\n",
    "#     3: 1, 4: 1, 5: 1,\n",
    "#     6: 2, 7: 2, 8: 2,\n",
    "#     9: 3, 10: 3, 11: 3\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdee6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #周期化处理\n",
    "# week_sum=df['日期'].dt.isocalendar().week\n",
    "# week_sum=week_sum%52\n",
    "# week_sum=week_sum.replace(0,52)\n",
    "\n",
    "# df['周sin']=np.sin(2*np.pi*week_sum/52)\n",
    "# df['周cos']=np.sin(2*np.pi*week_sum/52)\n",
    "\n",
    "# df['月sin']=np.sin(2*np.pi*week_sum/52)\n",
    "# df['月cos']=np.sin(2*np.pi*week_sum/52)\n",
    "\n",
    "# #归一化处理\n",
    "\n",
    "# def normalize_cyclical(col,period):\n",
    "#     return(col/period)-0.5\n",
    "# df['weekofyear']=normalize_cyclical(df['日期'].dt.isocalendar().week,52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7218ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 时间窗口统计\n",
    "# windows = [5, 20, 60]\n",
    "# for w in windows:\n",
    "#     df[f'收盘{w}'] = df['收盘'].rolling(w).mean()\n",
    "#     df[f'波动率{w}'] = df['收盘'].pct_change().rolling(w).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44500398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuyongze/vs/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_32054/3703768355.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()  # 混合精度训练\n",
      "/tmp/ipykernel_32054/3703768355.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()  # 混合精度训练\n",
      "/tmp/ipykernel_32054/3703768355.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 自动混合精度\n",
      "/tmp/ipykernel_32054/3703768355.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 自动混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9406.1758\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 166\u001b[39m\n\u001b[32m    163\u001b[39m     preds = trainer.evaluate(X_test, y_test)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 162\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    159\u001b[39m trainer = ModelTrainer(model)\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# 训练与评估\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m preds = trainer.evaluate(X_test, y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36mModelTrainer.train\u001b[39m\u001b[34m(self, X_train, y_train, epochs, lr)\u001b[39m\n\u001b[32m    119\u001b[39m     loss = criterion(outputs, y)\n\u001b[32m    121\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.scale(loss).backward()\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# 记录指标\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import math\n",
    "\n",
    "# 1. 数据预处理模块\n",
    "class StockData:\n",
    "    def __init__(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        # 自动查找日期列名\n",
    "        date_col = None\n",
    "        for col in df.columns:\n",
    "            if col.lower() in ['date', '日期']:\n",
    "                date_col = col\n",
    "                break\n",
    "        if date_col is not None:\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "            df = df.set_index(date_col)\n",
    "        # 自动适配英文或中文列名\n",
    "        col_map = {\n",
    "            'open': ['open', '开盘'],\n",
    "            'high': ['high', '最高'],\n",
    "            'low': ['low', '最低'],\n",
    "            'close': ['close', '收盘'],\n",
    "            'volume': ['volume', '成交量']\n",
    "        }\n",
    "        for std_col, candidates in col_map.items():\n",
    "            for c in candidates:\n",
    "                if c in df.columns:\n",
    "                    df.rename(columns={c: std_col}, inplace=True)\n",
    "                    break\n",
    "        self.data = df\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def create_features(self):\n",
    "        df = self.data.copy()\n",
    "        # 检查必须的列\n",
    "        for col in ['high', 'low', 'close', 'volume']:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"数据缺少必要列: {col}\")\n",
    "        df['HL_PCT'] = (df['high'] - df['low']) / df['close'] * 100\n",
    "        df['PCT_change'] = df['close'].pct_change()\n",
    "        windows = [5, 10, 20, 50]\n",
    "        for w in windows:\n",
    "            df[f'MA_{w}'] = df['close'].rolling(w).mean()\n",
    "            df[f'VOL_{w}'] = df['volume'].rolling(w).mean()\n",
    "        df['target'] = df['close'].shift(-1)\n",
    "        df = df.dropna()\n",
    "        features = [col for col in df.columns if col != 'target']\n",
    "        df[features] = df[features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        df[features] = self.scaler.fit_transform(df[features])\n",
    "        return df[features], df['target']\n",
    "\n",
    "# PositionalEncoding实现\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# 2. Transformer模型实现\n",
    "class StockTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model*4\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.encoder.out_features)\n",
    "        src = self.pos_encoder(src.unsqueeze(1)).squeeze(1)\n",
    "        output = self.transformer(src.unsqueeze(1))\n",
    "        return self.decoder(output.mean(dim=1)).squeeze()\n",
    "\n",
    "# 3. 训练与可视化模块\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.writer = SummaryWriter()\n",
    "        self.scaler = GradScaler()  # 混合精度训练\n",
    "        \n",
    "    def train(self, X_train, y_train, epochs=100, lr=0.001):\n",
    "        X = torch.FloatTensor(X_train.values).to(self.device)\n",
    "        y = torch.FloatTensor(y_train.values).to(self.device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():  # 自动混合精度\n",
    "                outputs = self.model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # 记录指标\n",
    "            self.writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        self.writer.close()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        with torch.no_grad():\n",
    "            X = torch.FloatTensor(X_test.values).to(self.device)\n",
    "            preds = self.model(X).cpu().numpy()\n",
    "            \n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.plot(y_test.index, y_test, label='True')\n",
    "            plt.plot(y_test.index, preds, label='Predicted')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            return preds\n",
    "\n",
    "# 4. 主程序\n",
    "def main():\n",
    "    # 数据准备\n",
    "    data = StockData('train.csv')\n",
    "    X, y = data.create_features()\n",
    "    \n",
    "    # 划分数据集\n",
    "    split = int(len(X)*0.8)\n",
    "    X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "    y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "    \n",
    "    # 训练配置\n",
    "    model = StockTransformer(input_dim=X.shape[1])\n",
    "    trainer = ModelTrainer(model)\n",
    "    \n",
    "    # 训练与评估\n",
    "    trainer.train(X_train, y_train)\n",
    "    preds = trainer.evaluate(X_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
