{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea63603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib as plt\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e47e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('test.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec708017",
   "metadata": {},
   "source": [
    "异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d69f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_feature_engineering(df):\n",
    "#     \"\"\"\n",
    "#     这段代码用于处理股票数据中的异常值，分为两部分：\n",
    "\n",
    "#     1. **IQR 法处理价格异常值**  \n",
    "#        - 针对“开盘”、“最高”、“最低”、“收盘”四个价格列，使用四分位数间距（IQR）方法检测和修正异常值。\n",
    "#        - 具体做法是：  \n",
    "#          - 计算每列的第 1 四分位数（Q1）和第 3 四分位数（Q3）。\n",
    "#          - 计算 IQR = Q3 - Q1。\n",
    "#          - 定义下界为 Q1 - 1.5*IQR，上界为 Q3 + 1.5*IQR。\n",
    "#          - 将低于下界的值替换为下界，高于上界的值替换为上界，其他值保持不变。\n",
    "#        - 这样可以有效减少极端异常值对后续分析的影响。\n",
    "\n",
    "#     2. **Z-score 法处理成交量异常值**  \n",
    "#        - 对“成交量”列，采用 Z-score 方法检测异常值。\n",
    "#        - 计算成交量的均值和标准差，将绝对偏离均值超过 3 个标准差的值视为异常。\n",
    "#        - 对于异常值，用成交量的中位数进行替换。\n",
    "#        - 这种方法适合处理近似正态分布的数据，能有效缓解极端值的影响。\n",
    "\n",
    "#     整体来看，这段代码的目的是通过合理的异常值处理，提高数据质量，为后续的特征工程和建模打下基础。\n",
    "#      \"\"\"\n",
    "#     df['日期']=pd.to_datetime(df['日期'])\n",
    "#       #IQR法处理价格异常值\n",
    "#     price=['开盘','最高','最低','收盘']\n",
    "#     for col in price:\n",
    "#         q1=df[col].quantile(0.25)\n",
    "#         q3=df[col].quantile(0.75)\n",
    "#         iqr=q3-q1\n",
    "#         lower_bound=q1-1.5*iqr\n",
    "#         upper_bound=q3+1.5*iqr\n",
    "#         df[col]=np.where(df[col]<lower_bound,lower_bound,np.where(df[col]>upper_bound,upper_bound,df[col]))\n",
    "\n",
    "\n",
    "#     #Z-score处理成交量异常值\n",
    "#     volume_mean=df['成交量'].mean()\n",
    "#     volume_std=df['成交量'].std()\n",
    "#     df['成交量']=np.where(np.abs(df['成交量']-volume_mean)>3*volume_std,df['成交量'].median(),df['成交量'])\n",
    "#     return df\n",
    "# df=stock_feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2eb7da",
   "metadata": {},
   "source": [
    "时间特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e299ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df['周内日'] = df['日期'].dt.dayofweek\n",
    "# df['月份'] = df['日期'].dt.month\n",
    "# df['年份'] = df['日期'].dt.year\n",
    "# df['季度'] = df['月份'].map({\n",
    "#     12: 0, 1: 0, 2: 0,\n",
    "#     3: 1, 4: 1, 5: 1,\n",
    "#     6: 2, 7: 2, 8: 2,\n",
    "#     9: 3, 10: 3, 11: 3\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdee6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #周期化处理\n",
    "# week_sum=df['日期'].dt.isocalendar().week\n",
    "# week_sum=week_sum%52\n",
    "# week_sum=week_sum.replace(0,52)\n",
    "\n",
    "# df['周sin']=np.sin(2*np.pi*week_sum/52)\n",
    "# df['周cos']=np.sin(2*np.pi*week_sum/52)\n",
    "\n",
    "# df['月sin']=np.sin(2*np.pi*week_sum/52)\n",
    "# df['月cos']=np.sin(2*np.pi*week_sum/52)\n",
    "\n",
    "# #归一化处理\n",
    "\n",
    "# def normalize_cyclical(col,period):\n",
    "#     return(col/period)-0.5\n",
    "# df['weekofyear']=normalize_cyclical(df['日期'].dt.isocalendar().week,52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7218ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 时间窗口统计\n",
    "# windows = [5, 20, 60]\n",
    "# for w in windows:\n",
    "#     df[f'收盘{w}'] = df['收盘'].rolling(w).mean()\n",
    "#     df[f'波动率{w}'] = df['收盘'].pct_change().rolling(w).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44500398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 17:41:28.237137: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-03 17:41:28.479553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748943688.565306     736 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748943688.586124     736 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748943688.761810     736 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748943688.761923     736 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748943688.761925     736 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748943688.761927     736 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-03 17:41:28.784855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/liuyongze/vs/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_736/3703768355.py:104: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()  # 混合精度训练\n",
      "/tmp/ipykernel_736/3703768355.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 自动混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 9399.9844\n",
      "Epoch 10, Loss: 9285.1738\n",
      "Epoch 20, Loss: 9148.1992\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import math\n",
    "\n",
    "# 1. 数据预处理模块\n",
    "class StockData:\n",
    "    def __init__(self, filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        # 自动查找日期列名\n",
    "        date_col = None\n",
    "        for col in df.columns:\n",
    "            if col.lower() in ['date', '日期']:\n",
    "                date_col = col\n",
    "                break\n",
    "        if date_col is not None:\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "            df = df.set_index(date_col)\n",
    "        # 自动适配英文或中文列名\n",
    "        col_map = {\n",
    "            'open': ['open', '开盘'],\n",
    "            'high': ['high', '最高'],\n",
    "            'low': ['low', '最低'],\n",
    "            'close': ['close', '收盘'],\n",
    "            'volume': ['volume', '成交量']\n",
    "        }\n",
    "        for std_col, candidates in col_map.items():\n",
    "            for c in candidates:\n",
    "                if c in df.columns:\n",
    "                    df.rename(columns={c: std_col}, inplace=True)\n",
    "                    break\n",
    "        self.data = df\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def create_features(self):\n",
    "        df = self.data.copy()\n",
    "        # 检查必须的列\n",
    "        for col in ['high', 'low', 'close', 'volume']:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"数据缺少必要列: {col}\")\n",
    "        df['HL_PCT'] = (df['high'] - df['low']) / df['close'] * 100\n",
    "        df['PCT_change'] = df['close'].pct_change()\n",
    "        windows = [5, 10, 20, 50]\n",
    "        for w in windows:\n",
    "            df[f'MA_{w}'] = df['close'].rolling(w).mean()\n",
    "            df[f'VOL_{w}'] = df['volume'].rolling(w).mean()\n",
    "        df['target'] = df['close'].shift(-1)\n",
    "        df = df.dropna()\n",
    "        features = [col for col in df.columns if col != 'target']\n",
    "        df[features] = df[features].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        df[features] = self.scaler.fit_transform(df[features])\n",
    "        return df[features], df['target']\n",
    "\n",
    "# PositionalEncoding实现\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# 2. Transformer模型实现\n",
    "class StockTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model*4\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src) * math.sqrt(self.encoder.out_features)\n",
    "        src = self.pos_encoder(src.unsqueeze(1)).squeeze(1)\n",
    "        output = self.transformer(src.unsqueeze(1))\n",
    "        return self.decoder(output.mean(dim=1)).squeeze()\n",
    "\n",
    "# 3. 训练与可视化模块\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.writer = SummaryWriter()\n",
    "        self.scaler = GradScaler()  # 混合精度训练\n",
    "        \n",
    "    def train(self, X_train, y_train, epochs=100, lr=0.001):\n",
    "        X = torch.FloatTensor(X_train.values).to(self.device)\n",
    "        y = torch.FloatTensor(y_train.values).to(self.device)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():  # 自动混合精度\n",
    "                outputs = self.model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            # 记录指标\n",
    "            self.writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        self.writer.close()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        with torch.no_grad():\n",
    "            X = torch.FloatTensor(X_test.values).to(self.device)\n",
    "            preds = self.model(X).cpu().numpy()\n",
    "            \n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.plot(y_test.index, y_test, label='True')\n",
    "            plt.plot(y_test.index, preds, label='Predicted')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            return preds\n",
    "\n",
    "# 4. 主程序\n",
    "def main():\n",
    "    # 数据准备\n",
    "    data = StockData('train.csv')\n",
    "    X, y = data.create_features()\n",
    "    \n",
    "    # 划分数据集\n",
    "    split = int(len(X)*0.8)\n",
    "    X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "    y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "    \n",
    "    # 训练配置\n",
    "    model = StockTransformer(input_dim=X.shape[1])\n",
    "    trainer = ModelTrainer(model)\n",
    "    \n",
    "    # 训练与评估\n",
    "    trainer.train(X_train, y_train)\n",
    "    preds = trainer.evaluate(X_test, y_test)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
